import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

# -----------------------------
# 1. Chebyshev Nodes and Diff Matrix
# -----------------------------
def chebyshev_nodes(N):
    k = torch.arange(N + 1, dtype=torch.float32)
    x = torch.cos(torch.pi * k / N)
    return x.unsqueeze(1)

def chebyshev_diff_matrix(N):
    x = torch.cos(torch.pi * torch.arange(N + 1) / N)
    c = torch.ones(N + 1)
    c[0], c[-1] = 2, 2
    c = c * ((-1) ** torch.arange(N + 1))
    X = x.repeat(N + 1, 1)
    dX = X - X.T
    D = torch.outer(c, 1 / c) / (dX + torch.eye(N + 1))
    D = D - torch.diag(torch.sum(D, dim=1))
    for i in range(N + 1):
        if i == 0:
            D[i, i] = (2 * N ** 2 + 1) / 6
        elif i == N:
            D[i, i] = -(2 * N ** 2 + 1) / 6
        else:
            D[i, i] = -x[i] / (2 * (1 - x[i] ** 2))
    return x.unsqueeze(1), D

# -----------------------------
# 2. Forcing Function
# -----------------------------
def forcing_function(x):
    return torch.sin(torch.pi * x)

# -----------------------------
# 3. Exact Solution for Helmholtz Equation
# -----------------------------
def exact_solution(x, k):
    pi_tensor = torch.tensor(torch.pi)  # make pi a tensor
    k_tensor = torch.tensor(k, dtype=torch.float32)  # ensure k is a tensor

    denom = k_tensor**2 - pi_tensor**2
    rhs = torch.sin(pi_tensor) / denom

    # Compute sin and cos for k
    sin_k = torch.sin(k_tensor)
    cos_k = torch.cos(k_tensor)
    sin_neg_k = torch.sin(-k_tensor)
    cos_neg_k = torch.cos(-k_tensor)

    # Build system matrix and RHS
    M = torch.stack([
        torch.tensor([sin_neg_k.item(), cos_neg_k.item()]),
        torch.tensor([sin_k.item(), cos_k.item()])
    ])
    b = torch.tensor([-rhs.item(), -rhs.item()])

    # Solve for A and B
    AB = torch.linalg.solve(M, b)
    A, B = AB[0], AB[1]

    # Compute solution
    u_p = torch.sin(pi_tensor * x) / denom
    u_h = A * torch.sin(k_tensor * x) + B * torch.cos(k_tensor * x)
    return u_p + u_h

# -----------------------------
# 4. DeepONet Model
# -----------------------------
class DeepONet(nn.Module):
    def __init__(self, branch_input_dim, trunk_input_dim, hidden_dim=64):
        super(DeepONet, self).__init__()
        self.branch_net = nn.Sequential(
            nn.Linear(branch_input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        self.trunk_net = nn.Sequential(
            nn.Linear(trunk_input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        self.output_layer = nn.Linear(hidden_dim, 1)

    def forward(self, f_input, x_input):
        branch_out = self.branch_net(f_input)
        trunk_out = self.trunk_net(x_input)
        combined = branch_out * trunk_out
        return self.output_layer(combined)

# -----------------------------
# 5. Training Setup
# -----------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
N = 20
k_val = 5.0
lr = 1e-3
epochs = 6000

x_nodes, D = chebyshev_diff_matrix(N)
x_nodes = x_nodes.to(device)
D = D.to(device)
f_vals = forcing_function(x_nodes).to(device)

model = DeepONet(branch_input_dim=1, trunk_input_dim=1).to(device)
optimizer = optim.Adam(model.parameters(), lr=lr)
mse = nn.MSELoss()

# -----------------------------
# 6. Training Loop
# -----------------------------
for epoch in range(epochs):
    model.train()
    optimizer.zero_grad()
    u_pred = model(f_vals, x_nodes)
    du = D @ u_pred
    d2u = D @ du
    residual = d2u + k_val**2 * u_pred - f_vals
    loss_pde = mse(residual, torch.zeros_like(residual))
    loss_bc = mse(u_pred[0], torch.tensor([0.0], device=device)) + mse(u_pred[-1], torch.tensor([0.0], device=device))
    loss = loss_pde + loss_bc
    loss.backward()
    optimizer.step()
    if epoch % 200 == 0:
        print(f"Epoch {epoch}, Loss: {loss.item():.6f}")

# -----------------------------
# 7. Evaluation and Plot
# -----------------------------
model.eval()
with torch.no_grad():
    x_plot = torch.linspace(-1, 1, 200).unsqueeze(1).to(device)
    f_plot = forcing_function(x_plot)
    u_pred_plot = model(f_plot, x_plot).cpu()
    u_exact_plot = exact_solution(x_plot.cpu(), k_val)

plt.figure(figsize=(8, 5))
plt.plot(x_plot.cpu().numpy(), u_pred_plot.numpy(), label='Predicted u(x)', linewidth=2)
plt.plot(x_plot.cpu().numpy(), u_exact_plot.numpy(), label='Exact u(x)', linestyle='--')
plt.title('DeepONet vs Exact Solution for Helmholtz Equation')
plt.xlabel('x')
plt.ylabel('u(x)')
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()



import torch
import math

def get_clenshaw_curtis_weights_mat(n: int) -> torch.Tensor:
    """
    Returns a diagonal matrix of Clenshaw-Curtis weights for n intervals (n+1 nodes).
    Nodes are assumed in descending order.
    """
    N = n + 1
    weights = torch.zeros(N, dtype=torch.float64)
    for k in range(N):
        s = 0.0
        for j in range(1, n // 2 + 1):
            s += (2 / (4 * j**2 - 1)) * math.cos(2 * j * k * math.pi / n)
        weights[k] = (2 / n) * (1 - s)
    # Reverse for descending Chebyshev nodes
    weights = torch.flip(weights, dims=[0])
    return torch.diag(weights)

# Test function: f(x) = cos(x)
def test_clenshaw_curtis(n):
    # Nodes in descending order
    nodes = torch.flip(torch.cos(torch.arange(0, n+1, dtype=torch.float64) * math.pi / n), dims=[0])
    f_values = torch.cos(nodes)
    
    # Get weights matrix
    W = get_clenshaw_curtis_weights_mat(n)
    
    # Approximate integral
    approx_integral = torch.matmul(W.diag(), f_values).sum().item()
    
    # Exact integral of cos(x) over [-1,1]
    exact_integral = math.sin(1) - math.sin(-1)  # = 2*sin(1)
    
    print(f"n = {n}")
    print(f"Approx integral: {approx_integral:.12f}")
    print(f"Exact integral:  {exact_integral:.12f}")
    print(f"Error:           {abs(approx_integral - exact_integral):.2e}")
    print("-" * 50)

# Run tests for a few n values
for n in [4, 8, 16, 32]:
    test_clenshaw_curtis(n)




